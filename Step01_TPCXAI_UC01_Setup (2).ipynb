{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store - Â Customer Segmentation\n",
    "\n",
    "## Setup Database Environment\n",
    "\n",
    "This Notebook is used to setup the required database objects including the source data for this use-case.\n",
    "\n",
    "We will create :\n",
    "- a database that will store all our database artifacts and raw source data\n",
    "- a database that will be setup to simulate ingesting of raw source data in an incrementing fashion\n",
    "- schemas to simulate different environments for development (TRAINING*) and production (SERVING*)\n",
    "- a data-scientist role that will have permissions to \n",
    "    - develop features and train models in our development schemas\n",
    "    - productionize our feature-engineering and ML pipeline in the production schemas\n",
    "\n",
    "In a 'live' environment you may have several roles with different permissions over Development and Production that are used to maintain separation of concerns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install SQLGlot** <br>\n",
    "Install SQLGlot with pip install in the conda environment **py-snowpark_df_ml_fs** by running the following command in the same terminal window.  We will use this package to format the SQL produced from Snowpark so that it is human-readable in the Dynamic Tables that Feature Store creates.  Installing within the Notebook, as other users have reported issues trying to install directly within the OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlglot[rs] in /opt/conda/lib/python3.9/site-packages (25.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install \"sqlglot[rs]\" --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.snowpark import Session, DataFrame, Window, WindowSpec\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.ml.utils import connection_params\n",
    "\n",
    "from useful_fns import run_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters\n",
    "\n",
    "Change the settings below if you want to if need to apply to your Snowflake Account.\n",
    "\n",
    "E.g. if you need to use a different role with ACCOUNTADMIN privileges to setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Roles\n",
    "aa_role = 'RAKESHGADIPARTHI'        # Either a ACCOUNTADMIN, or another role that has been granted ACCOUNTADMIN privileges\n",
    "fs_qs_role = 'RAKESHGADIPARTHI'       # The Data-Scientist role that will create an have permissions over the data, Feature-Store and Model-Registry\n",
    "\n",
    "# Database\n",
    "scale_factor               = 'SF0001'  # TPCXAI data comes in a number of Scale Factors.  For this quickstart we are using the lowest Scale Factor\n",
    "tpcxai_database_base       = f'TPCXAI_{scale_factor}_QUICKSTART' # The Database we will create to contain the base static data\n",
    "tpcxai_database_inc        = f'{tpcxai_database_base}_INC' # The Database we will create to contain the pseudo 'Live' incrementing data\n",
    "databases = [tpcxai_database_base,tpcxai_database_inc]\n",
    "\n",
    "# Schemas\n",
    "tpcxai_config_schema       = 'CONFIG'   # This Config Schema containing database artifacts to manage the Quickstart databases\n",
    "tpcxai_training_schema     = 'TRAINING' # The Training (Development) schema\n",
    "tpcxai_scoring_schema      = 'SCORING'  # The Scoring (Test) schema\n",
    "tpcxai_serving_schema      = 'SERVING'  # The Serving (Production) schema\n",
    "schemas = [tpcxai_training_schema, tpcxai_scoring_schema, tpcxai_serving_schema,]\n",
    "fq_schemas = []\n",
    "for d in databases:\n",
    "    for s in schemas:\n",
    "        fq_schemas.append(f'''{d}.{s}''')        \n",
    "\n",
    "# S3 bucket - public access bucket containing source data files\n",
    "s3_bucket = f's3://sfquickstarts/getting_started_with_snowflake_feature_store/'\n",
    "# Stage\n",
    "tpcxai_internal_stage = 'TPCXAI_STAGE'  # The Stage name we will use to represent the S3 bucket\n",
    "\n",
    "# Warehouse\n",
    "tpcxai_warehouse = f'FOSFOR_INSIGHT_WH'  # The name of the Warehouse we will use for any Quickstart processing\n",
    "#initial_wh_size = 'XSMALL' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SnowflakeLoginOptions() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = connection_params.SnowflakeLoginOptions(\"fya62509\")\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : SF$SERVICE$BkVeqMMnEH7UHgMtLujk1g\n",
      "Role                        : \"RAKESHGADIPARTHI\"\n",
      "Database                    : \"INSIGHT_DESIGNER_SPCS\"\n",
      "Schema                      : \"SPCS_SCHEMA\"\n",
      "Warehouse                   : None\n",
      "Snowflake version           : 8.27.1\n",
      "Snowpark for Python version : 1.20.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print(f'User                        : {snowflake_environment[0][0]}')\n",
    "print(f'Role                        : {session.get_current_role()}')\n",
    "print(f'Database                    : {session.get_current_database()}')\n",
    "print(f'Schema                      : {session.get_current_schema()}')\n",
    "print(f'Warehouse                   : {session.get_current_warehouse()}')\n",
    "print(f'Snowflake version           : {snowflake_environment[0][1]}')\n",
    "print(f'Snowpark for Python version : {snowpark_version[0]}.{snowpark_version[1]}.{snowpark_version[2]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role RAKESHGADIPARTHI \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use role RAKESHGADIPARTHI': [Row(status='Statement executed successfully.')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_sql(f'''use role {aa_role}''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role RAKESHGADIPARTHI \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01b607c3-0607-c887-0072-f3030fb0f26e: 003001 (42501): SQL access control error:\nInsufficient privileges to operate on account 'FYA62509'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m run_sql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124muse role \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maa_role\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'''\u001b[39m, session)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Role\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mrun_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43mcreate role if not exists \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfs_qs_role\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m run_sql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mgrant role \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfs_qs_role\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to role SYSADMIN\u001b[39m\u001b[38;5;124m'''\u001b[39m, session)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Warehouse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#run_sql(f'''create warehouse if not exists {tpcxai_warehouse}  warehouse_size = {initial_wh_size}''', session)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#run_sql(f'''grant all on warehouse {tpcxai_warehouse} to role {fs_qs_role}''', session)\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/notebooks/useful_fns.py:14\u001b[0m, in \u001b[0;36mrun_sql\u001b[0;34m(sql_statement, session)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_sql\u001b[39m(sql_statement, session):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Create a function to simplify the execution of SQL text strings via Snowpark.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    sql_statement : SQL statement as text string\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    session : Snowpark session.  If none, defaults session is assumed to be set in calling environmentÃ\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_statement\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sql_statement, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {sql_statement : result}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/telemetry.py:150\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 150\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\n\u001b[1;32m    152\u001b[0m     api_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;241m*\u001b[39mplan\u001b[38;5;241m.\u001b[39mapi_calls,\n\u001b[1;32m    154\u001b[0m         {TelemetryField\u001b[38;5;241m.\u001b[39mNAME\u001b[38;5;241m.\u001b[39mvalue: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    155\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/dataframe.py:596\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, statement_params, block, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03mlist of :class:`Row` objects.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    :meth:`collect_nowait()`\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m open_telemetry_context_manager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect, \u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_collect_with_tag_no_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/dataframe.py:644\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params, block, data_type, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;66;03m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mSKIP_LEVELS_THREE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:513\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    504\u001b[0m     is_in_stored_procedure()\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     )\n\u001b[1;32m    509\u001b[0m ):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync query is not supported in stored procedure yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m     )\n\u001b[0;32m--> 513\u001b[0m result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_set\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:195\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    193\u001b[0m         e\n\u001b[1;32m    194\u001b[0m     )\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:126\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:617\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m holder, id_ \u001b[38;5;129;01min\u001b[39;00m placeholders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    616\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 617\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    632\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    633\u001b[0m )\n\u001b[1;32m    634\u001b[0m result_meta \u001b[38;5;241m=\u001b[39m get_new_description(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:123\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    120\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:117\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    120\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    121\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:418\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         query_id_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:403\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_statement_params\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 403\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_notify_query_listener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:354\u001b[0m, in \u001b[0;36mServerConnection.execute_and_notify_query_listener\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_and_notify_query_listener\u001b[39m(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SnowflakeCursor:\n\u001b[0;32m--> 354\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    356\u001b[0m         QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    357\u001b[0m     )\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_cursor\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/cursor.py:1087\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _dataframe_ast)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1084\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1087\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    298\u001b[0m             error_class,\n\u001b[1;32m    299\u001b[0m             error_value,\n\u001b[1;32m    300\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    219\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01b607c3-0607-c887-0072-f3030fb0f26e: 003001 (42501): SQL access control error:\nInsufficient privileges to operate on account 'FYA62509'"
     ]
    }
   ],
   "source": [
    "# Setup master role and permissions\n",
    "run_sql(f'''use role {aa_role}''', session)\n",
    "\n",
    "# Role\n",
    "#run_sql(f'''create role if not exists {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant role {fs_qs_role} to role SYSADMIN''', session)\n",
    "\n",
    "# Warehouse\n",
    "#run_sql(f'''create warehouse if not exists {tpcxai_warehouse}  warehouse_size = {initial_wh_size}''', session)\n",
    "#run_sql(f'''grant all on warehouse {tpcxai_warehouse} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''use warehouse {tpcxai_warehouse}''', session)\n",
    "\n",
    "# Tasks\n",
    "#run_sql(f'''grant execute managed task on account to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant execute task on account to role {fs_qs_role}''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database -  BASE\n",
    "run_sql(f'''use role {aa_role}''', session)\n",
    "\n",
    "run_sql(f'''create database if not exists {tpcxai_database_base}''', session)\n",
    "run_sql(f'''grant all on database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on all schemas in database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on future schemas in database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "\n",
    "run_sql(f'''create database if not exists {tpcxai_database_inc}''', session)\n",
    "run_sql(f'''grant all on database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on all schemas in database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on future schemas in database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects in BASE database\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_base}.{tpcxai_training_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_training_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_serving_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_serving_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_scoring_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_scoring_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_config_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_config_schema}''', session)\n",
    "\n",
    "run_sql(f'''create file format if not exists {tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff type = 'parquet' ''', session)\n",
    "\n",
    "run_sql(f'''create stage if not exists {tpcxai_database_base}.{tpcxai_config_schema}.{tpcxai_internal_stage} \n",
    "        file_format = {tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff \n",
    "        url = '{s3_bucket}' ''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "\n",
    "# Calculate the DATE point difference between the source data and todays date.  \n",
    "# This reference point will be used to select a subset of the data for pre-loading, and the remainder will be incrementally ingested via a scheduled task.\n",
    "date_diff_to_source = session.sql('''select timestampdiff('days',  '2013-04-01', CURRENT_DATE() )::VARCHAR date_diff_to_source''').collect()[0][0]\n",
    "print('Difference in Days between source data and current date :',date_diff_to_source)\n",
    "\n",
    "##Â STATIC DATABASE SETUP - TPCXAI_SF001_QUICKSTART\n",
    "\n",
    "# Iteration over the Schemas creating and loading the required tables in each\n",
    "for s in [tpcxai_training_schema, tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "\n",
    "    # CUSTOMER\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.CUSTOMER\n",
    "                  (C_CUSTOMER_SK INTEGER,\n",
    "                   C_CUSTOMER_ID VARCHAR,\n",
    "                   C_CURRENT_ADDR_SK INTEGER,\n",
    "                   C_FIRST_NAME VARCHAR,\n",
    "                   C_LAST_NAME VARCHAR,\n",
    "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
    "                   C_BIRTH_DAY INTEGER,\n",
    "                   C_BIRTH_MONTH INTEGER,\n",
    "                   C_BIRTH_YEAR INTEGER,\n",
    "                   C_BIRTH_COUNTRY VARCHAR,\n",
    "                   C_LOGIN VARCHAR,\n",
    "                   C_EMAIL_ADDRESS VARCHAR,\n",
    "                   C_CLUSTER_ID INTEGER\n",
    "                  ) CLUSTER BY (C_CUSTOMER_SK);\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.CUSTOMER \n",
    "            FROM \n",
    "                 (select $1:C_CUSTOMER_SK::INTEGER,\n",
    "                         $1:C_CUSTOMER_ID::VARCHAR,\n",
    "                         $1:C_CURRENT_ADDR_SK::INTEGER,\n",
    "                         $1:C_FIRST_NAME::VARCHAR,\n",
    "                         $1:C_LAST_NAME::VARCHAR,\n",
    "                         $1:C_PREFERRED_CUST_FLAG::VARCHAR,\n",
    "                         $1:C_BIRTH_DAY::INTEGER,\n",
    "                         $1:C_BIRTH_MONTH::INTEGER,\n",
    "                         $1:C_BIRTH_YEAR::INTEGER,\n",
    "                         $1:C_BIRTH_COUNTRY::VARCHAR,\n",
    "                         $1:C_LOGIN::VARCHAR,\n",
    "                         $1:C_EMAIL_ADDRESS::VARCHAR,                        \n",
    "                         $1:C_CLUSTER_ID::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/CUSTOMER) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # ORDERS\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.ORDERS\n",
    "    (O_ORDER_ID INTEGER,\n",
    "     O_CUSTOMER_SK INTEGER,\n",
    "     ORDER_TS TIMESTAMP,\n",
    "     WEEKDAY VARCHAR,\n",
    "     ORDER_DATE DATE,\n",
    "     STORE INTEGER,\n",
    "     TRIP_TYPE INTEGER)\n",
    "     CLUSTER BY (O_ORDER_ID, ORDER_DATE)\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.ORDERS \n",
    "            FROM \n",
    "                 (select $1:O_ORDER_ID::INTEGER,\n",
    "                         $1:O_CUSTOMER_SK::INTEGER,\n",
    "                         timestampadd('MINS', UNIFORM( -1440 , 0 , random() ) ,timestampadd('days',   {date_diff_to_source}, $1:\"DATE\"::DATE)) ORDER_TS,\n",
    "                         decode(extract(dayofweek from ORDER_TS), 1, 'Monday', 2, 'Tuesday', 3, 'Wednesday', 4, 'Thursday',  5, 'Friday',  6, 'Saturday',  0, 'Sunday') WEEKDAY,\n",
    "                         TO_DATE(ORDER_TS) ORDER_DATE,\n",
    "                         $1:STORE::INTEGER,\n",
    "                         $1:TRIP_TYPE::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/ORDERS) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # LINEITEM\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.LINEITEM\n",
    "    (LI_ORDER_ID INTEGER,\n",
    "     LI_PRODUCT_ID INTEGER,\n",
    "     QUANTITY INTEGER,\n",
    "     PRICE DECIMAL(8,2))\n",
    "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.LINEITEM \n",
    "            FROM (select $1:LI_ORDER_ID::INTEGER,\n",
    "                         $1:LI_PRODUCT_ID::INTEGER,\n",
    "                         $1:QUANTITY::INTEGER,\n",
    "                         $1:PRICE::DECIMAL(8,2)\n",
    "                  from @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/LINEITEM) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # ORDER_RETURNS\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.ORDER_RETURNS\n",
    "    (OR_ORDER_ID INTEGER,\n",
    "     OR_PRODUCT_ID INTEGER,\n",
    "     OR_RETURN_QUANTITY INTEGER)\n",
    "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID);\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.ORDER_RETURNS \n",
    "            FROM (select $1:OR_ORDER_ID::INTEGER,\n",
    "                         $1:OR_PRODUCT_ID::INTEGER,\n",
    "                         $1:OR_RETURN_QUANTITY::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/ORDER_RETURNS) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â INCREMENTAL DATABASE SETUP - TPCXAI_SF001_QUICKSTART_INC\n",
    "\n",
    "# Training schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_training_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_training_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "# run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "\n",
    "# Serving schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_serving_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "\n",
    "# Scoring schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_scoring_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f'''use role {aa_role}''', session)\n",
    "for s in [tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "    run_sql(f'''drop table {tpcxai_database_inc}.{s}.CUSTOMER''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "# Set up Incremental SERVING & SCORING data maintenance\n",
    "for s in [tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.CUSTOMER\n",
    "                  (C_CUSTOMER_SK INTEGER,\n",
    "                   C_CUSTOMER_ID VARCHAR,\n",
    "                   C_CURRENT_ADDR_SK INTEGER,\n",
    "                   C_FIRST_NAME VARCHAR,\n",
    "                   C_LAST_NAME VARCHAR,\n",
    "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
    "                   C_BIRTH_DAY INTEGER,\n",
    "                   C_BIRTH_MONTH INTEGER,\n",
    "                   C_BIRTH_YEAR INTEGER,\n",
    "                   C_BIRTH_COUNTRY VARCHAR,\n",
    "                   C_LOGIN VARCHAR,\n",
    "                   C_EMAIL_ADDRESS VARCHAR,\n",
    "                   C_CLUSTER_ID INTEGER\n",
    "                  ) CLUSTER BY (C_CUSTOMER_SK)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''insert into {tpcxai_database_inc}.{s}.CUSTOMER select * from {tpcxai_database_base}.{s}.CUSTOMER order by C_CUSTOMER_SK ''', session)\n",
    "    \n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.ORDERS\n",
    "    (O_ORDER_ID INTEGER,\n",
    "     O_CUSTOMER_SK INTEGER,\n",
    "     ORDER_TS TIMESTAMP,\n",
    "     WEEKDAY VARCHAR,\n",
    "     ORDER_DATE DATE,\n",
    "     STORE INTEGER,\n",
    "     TRIP_TYPE INTEGER)\n",
    "     CLUSTER BY (O_ORDER_ID, ORDER_TS)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.LINEITEM\n",
    "    (LI_ORDER_ID INTEGER,\n",
    "     LI_PRODUCT_ID INTEGER,\n",
    "     QUANTITY INTEGER,\n",
    "     PRICE DECIMAL(8,2))\n",
    "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.ORDER_RETURNS\n",
    "    (OR_ORDER_ID INTEGER,\n",
    "     OR_PRODUCT_ID INTEGER,\n",
    "     OR_RETURN_QUANTITY INTEGER)\n",
    "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID)\n",
    "    ''', session)\n",
    "\n",
    "    # Streams\n",
    "    run_sql(f''' create or replace stream {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM on table {tpcxai_database_inc}.{s}.ORDERS''', session) \n",
    "    run_sql(f''' create or replace stream {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_ORDERRETURNS_STREAM on table {tpcxai_database_inc}.{s}.ORDERS''', session) \n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_LINEITEM_TASK\n",
    "    schedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\twhen SYSTEM$STREAM_HAS_DATA('{tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM')\n",
    "\tas insert into {tpcxai_database_inc}.{s}.LINEITEM\n",
    "select l.* \n",
    "from  {tpcxai_database_base}.{s}.LINEITEM l,\n",
    "      {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM o\n",
    "where l.LI_ORDER_ID = o.O_ORDER_ID\n",
    "order by LI_ORDER_ID, LI_PRODUCT_ID''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_LINEITEM_TASK resume''', session)\n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_RETURNS_TASK\n",
    "\tschedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\twhen SYSTEM$STREAM_HAS_DATA('{tpcxai_database_base}.CONFIG.{s}_ORDER_ORDERRETURNS_STREAM')\n",
    "\tas insert into {tpcxai_database_inc}.{s}.ORDER_RETURNS\n",
    "select o_r.* \n",
    "from {tpcxai_database_base}.{s}.ORDER_RETURNS o_r,\n",
    "     {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_ORDERRETURNS_STREAM o\n",
    "where o_r.OR_ORDER_ID = o.O_ORDER_ID\n",
    "order by OR_ORDER_ID, OR_PRODUCT_ID ''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_RETURNS_TASK resume ''', session)\n",
    "\n",
    "    run_sql(f''' insert into {tpcxai_database_inc}.{s}.ORDERS\n",
    "select * from {tpcxai_database_base}.{s}.ORDERS o\n",
    "where o.ORDER_TS < current_timestamp() \n",
    "order by ORDER_TS, O_CUSTOMER_SK ''', session)\n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_TASK\n",
    "\tschedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\tas insert into {tpcxai_database_inc}.{s}.ORDERS\n",
    "with o_max_timestamp as ( select max(ORDER_TS) max_ts\n",
    "                           from {tpcxai_database_inc}.{s}.ORDERS )\n",
    "     select O_ORDER_ID, O_CUSTOMER_SK, ORDER_TS, WEEKDAY, ORDER_DATE, STORE, TRIP_TYPE\n",
    "       from {tpcxai_database_base}.{s}.ORDERS o,\n",
    "            o_max_timestamp fmt\n",
    "      where \n",
    "            o.ORDER_TS <= current_timestamp() \n",
    "        and o.ORDER_TS > fmt.max_ts\n",
    "   order by ORDER_TS, O_CUSTOMER_SK ''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_TASK resume ''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up incremental database TRAINING schema that holds static, rather than incrementing database\n",
    "\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.CUSTOMER      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.CUSTOMER order by C_CUSTOMER_SK ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.LINEITEM      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.LINEITEM order by LI_ORDER_ID ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDERS        as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.ORDERS order by ORDER_TS, O_ORDER_ID, O_CUSTOMER_SK ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDER_RETURNS as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.ORDER_RETURNS order by OR_ORDER_ID, OR_PRODUCT_ID ''', session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
